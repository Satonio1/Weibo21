{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Edge('D:\\\\edgedriver\\\\msedgedriver.exe')\n",
    "#打开浏览器，记得先登陆\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"non_rumor_url.txt\",'r',encoding=\"utf-8\") as f:\n",
    "    urls = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"https://weibo.com/1608574203/K2HP9k7mO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_convert(t):\n",
    "    # t: 2020-12-31 12:35\n",
    "    if \"今天\" in t:\n",
    "        nian = datetime.datetime.now().year\n",
    "        yue = datetime.datetime.now().month\n",
    "        ri = datetime.datetime.now().day\n",
    "        t = \"{}年{}月{}日 {}\".format(nian,yue,ri,t[3:])\n",
    "        timeArray = time.strptime(t, \"%Y年%m月%d日 %H:%M\")\n",
    "    elif \"月\" in t:\n",
    "        timeArray = time.strptime(\"2021年\"+t, \"%Y年%m月%d日 %H:%M\")\n",
    "    elif \"刚\" in t:\n",
    "        return curr_time\n",
    "    elif \"秒前\" in t:\n",
    "        return curr_time - int(t[:-2])\n",
    "    elif \"分钟前\" in t:\n",
    "        return curr_time - int(t[:-3]) * 60\n",
    "    elif \"楼\" in t:\n",
    "        t = t.split(\" \")\n",
    "        return time_convert(t[1]+\" \"+t[2])\n",
    "    else:\n",
    "        timeArray = time.strptime(t, \"%Y-%m-%d %H:%M\")\n",
    "    timeStamp = int(time.mktime(timeArray))\n",
    "    return timeStamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/div/div[2]/div/div[2]/div[1]/div\"}\n  (Session info: MicrosoftEdge=90.0.818.56)\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a7b64569030e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mcurr_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mw_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/html/body/div[1]/div/div[2]/div/div[2]/div[1]/div\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mw_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m\"Pl\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//div/td[1]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mE:\\Program Files\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/div/div[2]/div/div[2]/div[1]/div\"}\n  (Session info: MicrosoftEdge=90.0.818.56)\n"
     ]
    }
   ],
   "source": [
    "for url in urls:\n",
    "    url = url.rstrip('\\n')\n",
    "    id = url.split('/')[-1]\n",
    "    if not os.path.exists(\"non_rumor/comment/\" + id + \"_comment.csv\"):\n",
    "        \n",
    "        browser.get(url + \"?type=comment\")\n",
    "        #获取当前时间\n",
    "        time.sleep(random.uniform(6,8))\n",
    "        curr_time = int(time.time())\n",
    "        w_id = browser.find_element_by_xpath(\"/html/body/div[1]/div/div[2]/div/div[2]/div[1]/div\").get_attribute(\"id\")\n",
    "        if w_id[:2]!=\"Pl\":\n",
    "            print(url)\n",
    "            continue\n",
    "        #懒加载\n",
    "        time.sleep(random.uniform(4,6))\n",
    "        all_window_height =  []  # 创建一个列表，用于记录每一次拖动滚动条后页面的最大高度\n",
    "        all_window_height.append(browser.execute_script(\"return document.body.scrollHeight;\")) #当前页面的最大高度加入列表\n",
    "        while True:\n",
    "            browser.execute_script(\"scroll(0,100000)\") # 执行拖动滚动条操作\n",
    "            time.sleep(random.uniform(4,6))\n",
    "            check_height = browser.execute_script(\"return document.body.scrollHeight;\")\n",
    "            if check_height == all_window_height[-1]:  #判断拖动滚动条后的最大高度与上一次的最大高度的大小，相等表明到了最底部\n",
    "                break\n",
    "            else:\n",
    "                all_window_height.append(check_height) #如果不想等，将当前页面最大高度加入列表。\n",
    "\n",
    "        #点击查看更多\n",
    "        time.sleep(random.uniform(4,6))\n",
    "        while True:\n",
    "            try:\n",
    "                watch_more = browser.find_element(By.XPATH,'//*[@id=\"' + w_id + '\"]/div/div/div/div[4]/div/div[@class=\"repeat_list\"]/div[2]/div/div/a')\n",
    "                \n",
    "                watch_more.click()\n",
    "                time.sleep(random.uniform(4,6))\n",
    "            except:\n",
    "                break\n",
    "        try:    \n",
    "            top = browser.find_element_by_xpath('//*[@id=\"base_scrollToTop\"]')\n",
    "            top.click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #源贴：\n",
    "        data1 = pd.DataFrame(columns=('uid','mid','user_name','text','parent','time'))\n",
    "        source = browser.find_element_by_xpath('//*[@id=\"' + w_id + '\"]/div/div/div')\n",
    "                                     \n",
    "        uid = source.get_attribute('tbinfo')\n",
    "        s_mid = source.get_attribute('mid')\n",
    "        uid = uid.split('=')[1]\n",
    "        user_name = source.find_element_by_xpath('./div[1]/div[@class=\"WB_detail\"]/div[1]/a[1]').text\n",
    "\n",
    "        t = time_convert(source.find_element_by_xpath('./div[1]/div[@class=\"WB_detail\"]/div[2]/a[1]').text)\n",
    "\n",
    "        text = source.find_element_by_xpath('./div[1]/div[@class=\"WB_detail\"]/div[4]').text\n",
    "        d = {'uid':uid,'mid':s_mid,'user_name':user_name,'time':t,'text':text,'parent':None,\"type\":0}\n",
    "        data1 = data1.append(d,ignore_index=True)\n",
    "\n",
    "        #评论\n",
    "        time.sleep(random.uniform(5,8))\n",
    "        comment1s = browser.find_elements_by_xpath('//*[@id=\"' + w_id + '\"]/div/div/div/div[@node-type=\"comment_detail\"]/div/div[@class=\"repeat_list\"]/div[@node-type=\"feed_list\"]/div/div[@class=\"list_ul\"]/div[@node-type=\"root_comment\"]')\n",
    "\n",
    "        for comment1 in comment1s: #循环\n",
    "            uid = comment1.find_element_by_xpath('./div[2]/div[1]/a[1]').get_attribute('usercard')\n",
    "            c_mid = comment1.get_attribute('comment_id')\n",
    "            if comment1.get_attribute('node-type')=='root_comment':\n",
    "                parent = s_mid\n",
    "            uid = uid.split('=')[1]\n",
    "            user_name = comment1.find_element_by_xpath('./div[2]/div[1]/a[1]').text\n",
    "            t = time_convert(comment1.find_element_by_xpath('./div[2]/div[@class=\"WB_func clearfix\"]/div[2]').text)\n",
    "            \n",
    "            text = comment1.find_element_by_xpath('./div[2]/div[1]').text\n",
    "            d = {'uid':uid,'mid':c_mid,'user_name':user_name,'time':t,'text':text[text.index('：')+1:],'parent':parent,\"type\":1}\n",
    "            data1 = data1.append(d,ignore_index = True)\n",
    "            while True:\n",
    "                try:\n",
    "                    watch_more = comment1.find_elements_by_xpath('./div[2]/div[@class=\"list_box_in S_bg3\"]')\n",
    "                    if len(watch_more)>1:\n",
    "                        watch_more = watch_more[1].find_element_by_xpath('./div/div[@node-type=\"more_child_comment\"]/div[1]/a[@action-type=\"click_more_child_comment_big\"]')\n",
    "                    else:\n",
    "                        watch_more = watch_more[0].find_element_by_xpath('./div/div[@node-type=\"more_child_comment\"]/div[1]/a[@action-type=\"click_more_child_comment_big\"]')\n",
    "                    watch_more.click()\n",
    "                    time.sleep(random.uniform(5,7))\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "            comment2s = comment1.find_elements_by_xpath('./div[@node-type=\"replywrap\"]/div[@class=\"list_box_in S_bg3\"]/div/div[@class=\"list_li S_line1 clearfix\"]')\n",
    "            for comment2 in comment2s:\n",
    "                uid = comment2.find_element_by_xpath('./div/div[1]/a').get_attribute('usercard')\n",
    "                mid = comment2.get_attribute('comment_id')\n",
    "                parent = c_mid\n",
    "                uid = uid.split('=')[1]\n",
    "                user_name = comment2.find_element_by_xpath('./div/div[1]/a').text\n",
    "                t = time_convert(comment2.find_element_by_xpath('./div/div[@class=\"WB_func clearfix\"]/div[2]').text)\n",
    "                text = comment2.find_element_by_xpath('./div/div[1]').text\n",
    "                d = {'uid':uid,'mid':mid,'user_name':user_name,'time':t,'text':text[text.index('：')+1:],'parent':parent,\"type\":2}\n",
    "                data1 = data1.append(d,ignore_index = True)\n",
    "\n",
    "        data1.to_csv(\"non_rumor/comment/\" + id +\"_comment.csv\",encoding='utf-8')\n",
    "\n",
    "    if not os.path.exists(\"non_rumor/repost/\" + id + \"_repost.csv\"):\n",
    "        #转发\n",
    "        browser.get(url + \"?type=repost\")\n",
    "        time.sleep(random.uniform(5,8))\n",
    "        curr_time = int(time.time())\n",
    "        time.sleep(random.uniform(6,8))\n",
    "        curr_time = int(time.time())\n",
    "        w_id = browser.find_element_by_xpath(\"/html/body/div[1]/div/div[2]/div/div[2]/div[1]/div\").get_attribute(\"id\")\n",
    "        if w_id[:2]!=\"Pl\":\n",
    "            print(url)\n",
    "            continue\n",
    "        source = browser.find_element_by_xpath('//*[@id=\"' + w_id + '\"]/div/div/div')\n",
    "        s_mid = source.get_attribute('mid')\n",
    "        data2 = pd.DataFrame(columns=('uid','mid','user_name','text','parent','time'))\n",
    "        while True:\n",
    "            L_reposts = len(browser.find_elements_by_xpath('//*[@id=\"' + w_id + '\"]/div/div/div/div[5]/div/div[@class=\"repeat_list\"]/div[2]/div/div[@class=\"list_li S_line1 clearfix\"]'))\n",
    "            r_xpath = '//*[@id=\"' + w_id + '\"]/div/div/div/div[5]/div/div[@class=\"repeat_list\"]/div[2]/div/div[@class=\"list_li S_line1 clearfix\"]'\n",
    "            for r in range(L_reposts):\n",
    "                uid = browser.find_elements_by_xpath(r_xpath)[r].find_element_by_xpath('./div[2]/div[1]/a[1]').get_attribute('usercard')\n",
    "                mid = browser.find_elements_by_xpath(r_xpath)[r].get_attribute('mid')\n",
    "                #if comment1.get_attribute('node-type')=='root_comment':\n",
    "                parent = s_mid\n",
    "                uid = uid.split('=')[1]\n",
    "                user_name = browser.find_elements_by_xpath(r_xpath)[r].find_element_by_xpath('./div[2]/div[1]/a').text\n",
    "                t = time_convert(browser.find_elements_by_xpath(r_xpath)[r].find_element_by_xpath('./div[2]/div[@class=\"WB_func clearfix\"]/div[2]').text)\n",
    "                text = browser.find_elements_by_xpath(r_xpath)[r].find_element_by_xpath('./div[2]/div[1]').text\n",
    "                d = {'uid':uid,'mid':mid,'user_name':user_name,'time':t,'text':text[text.index('：')+1:],'parent':parent,\"type\":3}\n",
    "                data2 = data2.append(d,ignore_index = True)\n",
    "            try:\n",
    "                page = browser.find_element_by_xpath('//*[@id=\"' + w_id + '\"]/div/div/div/div[5]/div/div[@class=\"repeat_list\"]/div[2]/div/div[@class=\"WB_cardpage S_line1\"]/div[@class=\"W_pages\"]/a[@class=\"page next S_txt1 S_line1\"]')     \n",
    "                while True:\n",
    "                    browser.execute_script(\"scroll(0,100000)\") # 执行拖动滚动条操作\n",
    "                    time.sleep(random.uniform(4,6))\n",
    "                    check_height = browser.execute_script(\"return document.body.scrollHeight;\")\n",
    "                    if check_height == all_window_height[-1]:  #判断拖动滚动条后的最大高度与上一次的最大高度的大小，相等表明到了最底\n",
    "                        break\n",
    "                    else:\n",
    "                        all_window_height.append(check_height) #如果不想等，将当前页面最大高度加入列表。\n",
    "           \n",
    "                page.click()\n",
    "                time.sleep(random.uniform(4,6))\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        data2.to_csv(\"non_rumor/repost/\" + id +\"_repost.csv\",encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"non_rumor/repost/\" + \"K2HP9k7mO\" + \"_repost.csv\"):\n",
    "        #转发\n",
    "        browser.get(urls[0] + \"?type=repost\")\n",
    "        time.sleep(random.uniform(5,8))\n",
    "        curr_time = int(time.time())\n",
    "        time.sleep(random.uniform(6,8))\n",
    "        curr_time = int(time.time())\n",
    "        w_id = browser.find_element_by_xpath(\"/html/body/div[1]/div/div[2]/div/div[2]/div[1]/div\").get_attribute(\"id\")\n",
    "        if w_id[:2]!=\"Pl\":\n",
    "            print(url)\n",
    "            #continue\n",
    "        source = browser.find_element_by_xpath('//*[@id=\"' + w_id + '\"]/div/div/div')\n",
    "        s_mid = source.get_attribute('mid')\n",
    "        data2 = pd.DataFrame(columns=('uid','mid','user_name','text','parent','time'))\n",
    "        while True:\n",
    "            L_reposts = len(browser.find_elements_by_xpath('//*[@id=\"' + w_id + '\"]/div/div/div/div[5]/div/div[@class=\"repeat_list\"]/div[2]/div/div[@class=\"list_li S_line1 clearfix\"]'))\n",
    "            r_xpath = '//*[@id=\"' + w_id + '\"]/div/div/div/div[5]/div/div[@class=\"repeat_list\"]/div[2]/div/div[@class=\"list_li S_line1 clearfix\"]'\n",
    "            for r in range(L_reposts):\n",
    "                uid = browser.find_elements_by_xpath(r_xpath)[r].find_element_by_xpath('./div[2]/div[1]/a[1]').get_attribute('usercard')\n",
    "                mid = browser.find_elements_by_xpath(r_xpath)[r].get_attribute('mid')\n",
    "                #if comment1.get_attribute('node-type')=='root_comment':\n",
    "                parent = s_mid\n",
    "                uid = uid.split('=')[1]\n",
    "                user_name = browser.find_elements_by_xpath(r_xpath)[r].find_element_by_xpath('./div[2]/div[1]/a').text\n",
    "                t = time_convert(browser.find_elements_by_xpath(r_xpath)[r].find_element_by_xpath('./div[2]/div[@class=\"WB_func clearfix\"]/div[2]').text)\n",
    "                text = browser.find_elements_by_xpath(r_xpath)[r].find_element_by_xpath('./div[2]/div[1]').text\n",
    "                d = {'uid':uid,'mid':mid,'user_name':user_name,'time':t,'text':text[text.index('：')+1:],'parent':parent,\"type\":3}\n",
    "                data2 = data2.append(d,ignore_index = True)\n",
    "            try:\n",
    "                page = browser.find_element_by_xpath('//*[@id=\"' + w_id + '\"]/div/div/div/div[5]/div/div[@class=\"repeat_list\"]/div[2]/div/div[@class=\"WB_cardpage S_line1\"]/div[@class=\"W_pages\"]/a[@class=\"page next S_txt1 S_line1\"]')     \n",
    "                while True:\n",
    "                    browser.execute_script(\"scroll(0,100000)\") # 执行拖动滚动条操作\n",
    "                    time.sleep(random.uniform(4,6))\n",
    "                    check_height = browser.execute_script(\"return document.body.scrollHeight;\")\n",
    "                    if check_height == all_window_height[-1]:  #判断拖动滚动条后的最大高度与上一次的最大高度的大小，相等表明到了最底\n",
    "                        break\n",
    "                    else:\n",
    "                        all_window_height.append(check_height) #如果不想等，将当前页面最大高度加入列表。\n",
    "           \n",
    "                page.click()\n",
    "                time.sleep(random.uniform(4,6))\n",
    "            except:\n",
    "                break\n",
    "\n",
    "        data2.to_csv(\"non_rumor/repost/\" +\"K2HP9k7mO\"+\"_repost.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv(\"non_rumor/repost/\" + id +\"_repost.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 19\n<selenium.webdriver.remote.webelement.WebElement (session=\"dc6066034518a1e7323836d2cfc0abb1\", element=\"09b5a0e1-fd45-4c24-b761-b1fe8ab67a37\")>\n"
     ]
    }
   ],
   "source": [
    "L_reposts = len(browser.find_elements_by_xpath(r_xpath))\n",
    "r_xpath = '//*[@id=\"' + w_id + '\"]/div/div/div/div[5]/div/div[@class=\"repeat_list\"]/div[2]/div/div[@class=\"list_li S_line1 clearfix\"]'\n",
    "for r in range(L_reposts):\n",
    "    print(r,L_reposts)\n",
    "    print(browser.find_element_by_xpath(r_xpath))#.find_elements_by_xpath('./div[2]/div[1]/a[1]').get_attribute('usercard')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'//*[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div/div[5]/div/div[@class=\"repeat_list\"]/div[2]/div/div[@class=\"list_li S_line1 clearfix\"]'"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "r_xpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get(\"https://weibo.com/6003555098/JysY2jISR?type=comment\")\n",
    "#获取当前时间\n",
    "time.sleep(3)\n",
    "curr_time = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time.sleep(3)\n",
    "all_window_height =  []  # 创建一个列表，用于记录每一次拖动滚动条后页面的最大高度\n",
    "all_window_height.append(browser.execute_script(\"return document.body.scrollHeight;\")) #当前页面的最大高度加入列表\n",
    "while True:\n",
    "        browser.execute_script(\"scroll(0,100000)\") # 执行拖动滚动条操作\n",
    "        time.sleep(4)\n",
    "        check_height = browser.execute_script(\"return document.body.scrollHeight;\")\n",
    "        if check_height == all_window_height[-1]:  #判断拖动滚动条后的最大高度与上一次的最大高度的大小，相等表明到了最底部\n",
    "            break\n",
    "        else:\n",
    "            all_window_height.append(check_height) #如果不想等，将当前页面最大高度加入列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#点击查看更多\n",
    "while True:\n",
    "    try:\n",
    "        watch_more = browser.find_element(By.XPATH,'//*[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div/div[4]/div/div[@class=\"repeat_list\"]/div[2]/div/div/a')\n",
    "        \n",
    "        watch_more.click()\n",
    "        time.sleep(random.uniform(4,6))\n",
    "    except:\n",
    "        break\n",
    "top = browser.find_element_by_xpath('//*[@id=\"base_scrollToTop\"]')\n",
    "top.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#源贴：\n",
    "data1 = pd.DataFrame(columns=('uid','mid','user_name','text','parent','time'))\n",
    "\n",
    "source = browser.find_element_by_xpath('//*[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div')\n",
    "\n",
    "uid = source.get_attribute('tbinfo')\n",
    "s_mid = source.get_attribute('mid')\n",
    "uid = uid.split('=')[1]\n",
    "user_name = source.find_element_by_xpath('./div[1]/div[@class=\"WB_detail\"]/div[1]/a[1]').text\n",
    "\n",
    "t = time_convert(source.find_element_by_xpath('./div[1]/div[@class=\"WB_detail\"]/div[2]/a[1]').text)\n",
    "\n",
    "text = source.find_element_by_xpath('./div[1]/div[@class=\"WB_detail\"]/div[4]').text\n",
    "d = {'uid':uid,'mid':s_mid,'user_name':user_name,'time':t,'text':text,'parent':None,\"type\":0}\n",
    "data1 = data1.append(d,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': '1688807837',\n",
       " 'mid': '4581040163400699',\n",
       " 'user_name': '天使芯-保护动物',\n",
       " 'time': 1607688540,\n",
       " 'text': '📣📣震惊世界\\n坐标上海，又一起警察当街残杀走失萨摩犬，手段残忍到令人发指[发怒][发怒][发怒]\\n出事地点：上海浦东上浦路165弄。\\n时间：2020年12月11日上午。在小区内走失的萨摩耶二次遭到暴力毒打。第一次牙齿给打掉，第二次直接打死（有照片作证）\\n\\n☎️投诉电话：️02112345\\n☎️浦东分局督察：02168546109\\n☎️打死萨摩耶的东明路派出所电话：\\n02122044671（东明派出所地址：浦东新区南林路738号）\\n☎️ 投诉警察违规执法热线：12389\\n\\n国家农业部4499号文件有三个要求：1，要求各地政府善待流浪动物，扩建犬舍妥善安置。2，给抓捕回来的流浪狗打疫苗做绝育。3，开放领养。\\n东明派出所民警严重违反国家农业部4499号文件精神，与中央政府倡导的构建文明和谐的社会背道而驰！是赤裸裸的暴力执法！一定一定要追究相关的法律责任！\\n东明派出所谁给你们的权利这样滥杀无辜？？？ #上海走丢有芯片萨摩被当街打死#',\n",
       " 'parent': None,\n",
       " 'type': 0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"40f278a72884695e22fc1039a2f497d7\", element=\"c1723d85-520d-41ef-aa70-4c6ac0968712\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"40f278a72884695e22fc1039a2f497d7\", element=\"c1723d85-520d-41ef-aa70-4c6ac0968712\")>]\n",
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"40f278a72884695e22fc1039a2f497d7\", element=\"c1723d85-520d-41ef-aa70-4c6ac0968712\")>]\n"
     ]
    }
   ],
   "source": [
    "#评论\n",
    "#comment_cnt = int(browser.find_element_by_xpath('//*[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div/div[4]/div').get_attribute(\"count\")) #评论数量\n",
    "time.sleep(random.uniform(4,6))\n",
    "comment1s = browser.find_elements_by_xpath('//*[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div/div[@node-type=\"comment_detail\"]/div/div[@class=\"repeat_list\"]/div[@node-type=\"feed_list\"]/div/div[@class=\"list_ul\"]/div[@node-type=\"root_comment\"]')\n",
    "\n",
    "for comment1 in comment1s: #循环\n",
    "    #try:\n",
    "    #    comment1 = browser.find_element_by_xpath('//*[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div/div[4]/div/div[3]/div[2]/div/div/div[' + str(num1) + ']')\n",
    "    #except:\n",
    "    #    break\n",
    "    uid = comment1.find_element_by_xpath('./div[2]/div[1]/a[1]').get_attribute('usercard')\n",
    "    c_mid = comment1.get_attribute('comment_id')\n",
    "    if comment1.get_attribute('node-type')=='root_comment':\n",
    "        parent = s_mid\n",
    "    uid = uid.split('=')[1]\n",
    "    user_name = comment1.find_element_by_xpath('./div[2]/div[1]/a[1]').text\n",
    "    t = time_convert(comment1.find_element_by_xpath('./div[2]/div[@class=\"WB_func clearfix\"]/div[2]').text)\n",
    "    \n",
    "    text = comment1.find_element_by_xpath('./div[2]/div[1]').text\n",
    "    d = {'uid':uid,'mid':c_mid,'user_name':user_name,'time':t,'text':text[text.index('：')+1:],'parent':parent,\"type\":1}\n",
    "    data1 = data1.append(d,ignore_index = True)\n",
    "    while True:\n",
    "        try:\n",
    "            watch_more = comment1.find_elements_by_xpath('./div[2]/div[@class=\"list_box_in S_bg3\"]')\n",
    "            print(watch_more)\n",
    "            if len(watch_more)>1:\n",
    "                watch_more = watch_more[1].find_element_by_xpath('./div/div[@node-type=\"more_child_comment\"]/div[1]/a[@action-type=\"click_more_child_comment_big\"]')\n",
    "            else:\n",
    "                watch_more = watch_more[0].find_element_by_xpath('./div/div[@node-type=\"more_child_comment\"]/div[1]/a[@action-type=\"click_more_child_comment_big\"]')\n",
    "            time.sleep(3)\n",
    "            watch_more.click()\n",
    "            time.sleep(random.uniform(5,7))\n",
    "        except:\n",
    "            break\n",
    "    break\n",
    "    comment2s = comment1.find_elements_by_xpath('./div[@node-type=\"replywrap\"]/div[@class=\"list_box_in S_bg3\"]/div/div[@class=\"list_li S_line1 clearfix\"]')\n",
    "    for comment2 in comment2s:\n",
    "        uid = comment2.find_element_by_xpath('./div/div[1]/a').get_attribute('usercard')\n",
    "        mid = comment2.get_attribute('comment_id')\n",
    "        parent = c_mid\n",
    "        uid = uid.split('=')[1]\n",
    "        user_name = comment2.find_element_by_xpath('./div/div[1]/a').text\n",
    "        t = time_convert(comment2.find_element_by_xpath('./div/div[@class=\"WB_func clearfix\"]/div[2]').text)\n",
    "        text = comment2.find_element_by_xpath('./div/div[1]').text\n",
    "        d = {'uid':uid,'mid':mid,'user_name':user_name,'time':t,'text':text[text.index('：')+1:],'parent':parent,\"type\":2}\n",
    "        data1 = data1.append(d,ignore_index = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#转发\n",
    "browser.get('https://weibo.com/6003555098/JysY2jISR?type=repost')\n",
    "time.sleep(random.uniform(4,6))\n",
    "curr_time = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame(columns=('uid','mid','user_name','text','parent','time'))\n",
    "while True:\n",
    "    reposts = browser.find_elements_by_xpath('//*[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div/div[5]/div/div[@class=\"repeat_list\"]/div[2]/div/div[@class=\"list_li S_line1 clearfix\"]')\n",
    "    for repost in reposts:\n",
    "        uid = repost.find_element_by_xpath('./div[2]/div[1]/a[1]').get_attribute('usercard')\n",
    "        mid = repost.get_attribute('mid')\n",
    "        #if comment1.get_attribute('node-type')=='root_comment':\n",
    "        parent = s_mid\n",
    "        uid = uid.split('=')[1]\n",
    "        user_name = repost.find_element_by_xpath('./div[2]/div[1]/a').text\n",
    "        t = time_convert(repost.find_element_by_xpath('./div[2]/div[@class=\"WB_func clearfix\"]/div[2]').text)\n",
    "        text = repost.find_element_by_xpath('./div[2]/div[1]').text\n",
    "        d = {'uid':uid,'mid':mid,'user_name':user_name,'time':t,'text':text[text.index('：')+1:],'parent':parent,\"type\":3}\n",
    "        data2 = data2.append(d,ignore_index = True)\n",
    "    try:\n",
    "        page = browser.find_element_by_xpath('//*[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div/div[5]/div/div[@class=\"repeat_list\"]/div[2]/div/div[@class=\"WB_cardpage S_line1\"]/div[@class=\"W_pages\"]/a[@class=\"page next S_txt1 S_line1\"]')\n",
    "        page.click()\n",
    "        time.sleep(random.uniform(4,6))\n",
    "    except:\n",
    "        break\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv(s_mid+\"_comment.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv(s_mid+\"_repost.csv\",encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            uid               mid        user_name  \\\n",
       "0    5079202686  4495141022901027  liuwentingchina   \n",
       "1    5772668165  4495140905560250          EnAdage   \n",
       "2    2787493700  4495140883882787        摩诃有量-风中吃药   \n",
       "3    5129300878  4495140788243852             最终致意   \n",
       "4    5887160511  4495140699990053        cocoluna_   \n",
       "..          ...               ...              ...   \n",
       "135  6132884038  4495134395371636       富贵儿富贵儿鸭oao   \n",
       "136  3032306195  4495134378512972              龙大头   \n",
       "137  1779851063  4495134311321970          酒窝宝宝甜甜甜   \n",
       "138  3225834805  4495134287042050          黑猫白猫猫花猫   \n",
       "139  1743494251  4495134282693250  Isabelle_n_pugs   \n",
       "\n",
       "                                                  text            parent  \\\n",
       "0                                   牛掰牛掰 有这么多记录照片都可以这样  4494815544688017   \n",
       "1                打的就是你这种人，可真不要脸啊//@Sirizjrng:牛逼牛逼这都能打拳  4494815544688017   \n",
       "2    //@兔唧唧_ :我之前很注意广州地铁的宣传图，大概是三男一女或者五男二女的比例为什么我这么...  4494815544688017   \n",
       "3                                                 无fk说  4494815544688017   \n",
       "4    //@陈猿猿李狮狮:又转发到了我这里//@幸运的小五在上海: 没有田也没有园//@满城狂草:...  4494815544688017   \n",
       "..                                                 ...               ...   \n",
       "135  //@龙猫自在://@故园湾里://@陈猿猿李狮狮:又转发到了我这里//@幸运的小五在上海:...  4494815544688017   \n",
       "136  贱不贱？超贱！//@陈猿猿李狮狮:又转发到了我这里//@幸运的小五在上海: 没有田也没有园/...  4494815544688017   \n",
       "137  //@胖次胖次君://@十一点之前必睡觉://@代表人类给你一个吻://@陈猿猿李狮狮:又转...  4494815544688017   \n",
       "138  为什么//@沈夜焰://@卡李://@一生不羁要上天://@裴图龙云:这就是赤裸裸得在抢功！...  4494815544688017   \n",
       "139                                       请你们#看见女性劳动者#  4494815544688017   \n",
       "\n",
       "           time  type  \n",
       "0    1587208560   3.0  \n",
       "1    1587208560   3.0  \n",
       "2    1587208560   3.0  \n",
       "3    1587208500   3.0  \n",
       "4    1587208500   3.0  \n",
       "..          ...   ...  \n",
       "135  1587207000   3.0  \n",
       "136  1587207000   3.0  \n",
       "137  1587206940   3.0  \n",
       "138  1587206940   3.0  \n",
       "139  1587206940   3.0  \n",
       "\n",
       "[140 rows x 7 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>uid</th>\n      <th>mid</th>\n      <th>user_name</th>\n      <th>text</th>\n      <th>parent</th>\n      <th>time</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5079202686</td>\n      <td>4495141022901027</td>\n      <td>liuwentingchina</td>\n      <td>牛掰牛掰 有这么多记录照片都可以这样</td>\n      <td>4494815544688017</td>\n      <td>1587208560</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5772668165</td>\n      <td>4495140905560250</td>\n      <td>EnAdage</td>\n      <td>打的就是你这种人，可真不要脸啊//@Sirizjrng:牛逼牛逼这都能打拳</td>\n      <td>4494815544688017</td>\n      <td>1587208560</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2787493700</td>\n      <td>4495140883882787</td>\n      <td>摩诃有量-风中吃药</td>\n      <td>//@兔唧唧_ :我之前很注意广州地铁的宣传图，大概是三男一女或者五男二女的比例为什么我这么...</td>\n      <td>4494815544688017</td>\n      <td>1587208560</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5129300878</td>\n      <td>4495140788243852</td>\n      <td>最终致意</td>\n      <td>无fk说</td>\n      <td>4494815544688017</td>\n      <td>1587208500</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5887160511</td>\n      <td>4495140699990053</td>\n      <td>cocoluna_</td>\n      <td>//@陈猿猿李狮狮:又转发到了我这里//@幸运的小五在上海: 没有田也没有园//@满城狂草:...</td>\n      <td>4494815544688017</td>\n      <td>1587208500</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>6132884038</td>\n      <td>4495134395371636</td>\n      <td>富贵儿富贵儿鸭oao</td>\n      <td>//@龙猫自在://@故园湾里://@陈猿猿李狮狮:又转发到了我这里//@幸运的小五在上海:...</td>\n      <td>4494815544688017</td>\n      <td>1587207000</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>136</th>\n      <td>3032306195</td>\n      <td>4495134378512972</td>\n      <td>龙大头</td>\n      <td>贱不贱？超贱！//@陈猿猿李狮狮:又转发到了我这里//@幸运的小五在上海: 没有田也没有园/...</td>\n      <td>4494815544688017</td>\n      <td>1587207000</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>1779851063</td>\n      <td>4495134311321970</td>\n      <td>酒窝宝宝甜甜甜</td>\n      <td>//@胖次胖次君://@十一点之前必睡觉://@代表人类给你一个吻://@陈猿猿李狮狮:又转...</td>\n      <td>4494815544688017</td>\n      <td>1587206940</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>3225834805</td>\n      <td>4495134287042050</td>\n      <td>黑猫白猫猫花猫</td>\n      <td>为什么//@沈夜焰://@卡李://@一生不羁要上天://@裴图龙云:这就是赤裸裸得在抢功！...</td>\n      <td>4494815544688017</td>\n      <td>1587206940</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>1743494251</td>\n      <td>4495134282693250</td>\n      <td>Isabelle_n_pugs</td>\n      <td>请你们#看见女性劳动者#</td>\n      <td>4494815544688017</td>\n      <td>1587206940</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>140 rows × 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page= 1\n",
      "page= 2\n",
      "page= 3\n",
      "page= 4\n",
      "page= 5\n",
      "page= 6\n",
      "page= 7\n",
      "page= 8\n",
      "page= 9\n",
      "page= 10\n",
      "page= 11\n",
      "page= 12\n",
      "page= 13\n",
      "page= 14\n",
      "page= 15\n",
      "page= 16\n",
      "page= 17\n",
      "page= 18\n",
      "page= 19\n",
      "page= 20\n",
      "page= 21\n",
      "page= 22\n",
      "page= 23\n",
      "page= 24\n",
      "page= 25\n",
      "page= 26\n",
      "page= 27\n",
      "page= 28\n",
      "page= 29\n",
      "page= 30\n",
      "page= 31\n",
      "page= 32\n",
      "page= 33\n",
      "page= 34\n",
      "page= 35\n",
      "page= 36\n",
      "page= 37\n",
      "page= 38\n",
      "page= 39\n",
      "page= 40\n",
      "page= 41\n",
      "page= 42\n",
      "page= 43\n",
      "page= 44\n",
      "page= 45\n",
      "page= 46\n",
      "page= 47\n",
      "page= 48\n",
      "page= 49\n",
      "page= 50\n",
      "page= 51\n",
      "page= 52\n",
      "page= 53\n",
      "page= 54\n",
      "page= 55\n",
      "page= 56\n",
      "page= 57\n",
      "page= 58\n",
      "page= 59\n",
      "page= 60\n",
      "page= 61\n",
      "page= 62\n",
      "page= 63\n",
      "page= 64\n",
      "page= 65\n",
      "page= 66\n",
      "page= 67\n",
      "page= 68\n",
      "page= 69\n",
      "page= 70\n",
      "page= 71\n",
      "page= 72\n",
      "page= 73\n",
      "page= 74\n",
      "page= 75\n",
      "page= 76\n",
      "page= 77\n",
      "page= 78\n",
      "page= 79\n",
      "page= 80\n",
      "page= 81\n",
      "page= 82\n",
      "page= 83\n",
      "page= 84\n",
      "page= 85\n",
      "page= 86\n",
      "page= 87\n",
      "page= 88\n",
      "page= 89\n",
      "page= 90\n",
      "page= 91\n",
      "page= 92\n",
      "page= 93\n",
      "page= 94\n",
      "page= 95\n",
      "page= 96\n",
      "page= 97\n",
      "page= 98\n",
      "page= 99\n",
      "page= 100\n",
      "page= 101\n",
      "page= 102\n",
      "page= 103\n",
      "page= 104\n",
      "page= 105\n",
      "page= 106\n",
      "page= 107\n",
      "page= 108\n",
      "page= 109\n",
      "page= 110\n",
      "page= 111\n",
      "page= 112\n",
      "page= 113\n",
      "page= 114\n",
      "page= 115\n",
      "page= 116\n",
      "page= 117\n",
      "page= 118\n",
      "page= 119\n",
      "page= 120\n",
      "page= 121\n",
      "page= 122\n",
      "page= 123\n",
      "page= 124\n",
      "page= 125\n",
      "page= 126\n",
      "page= 127\n",
      "page= 128\n",
      "page= 129\n",
      "page= 130\n",
      "page= 131\n",
      "page= 132\n",
      "page= 133\n",
      "page= 134\n",
      "page= 135\n",
      "page= 136\n",
      "page= 137\n",
      "page= 138\n",
      "page= 139\n",
      "page= 140\n",
      "page= 141\n",
      "page= 142\n",
      "page= 143\n",
      "page= 144\n",
      "page= 145\n",
      "page= 146\n",
      "page= 147\n",
      "page= 148\n",
      "page= 149\n",
      "page= 150\n",
      "page= 151\n",
      "page= 152\n",
      "page= 153\n",
      "page= 154\n",
      "page= 155\n",
      "page= 156\n",
      "page= 157\n",
      "page= 158\n",
      "page= 159\n",
      "page= 160\n",
      "page= 161\n",
      "page= 162\n",
      "page= 163\n",
      "page= 164\n",
      "page= 165\n",
      "page= 166\n",
      "page= 167\n",
      "page= 168\n",
      "page= 169\n",
      "page= 170\n",
      "page= 171\n",
      "page= 172\n",
      "page= 173\n",
      "page= 174\n",
      "page= 175\n",
      "page= 176\n",
      "page= 177\n",
      "page= 178\n",
      "page= 179\n",
      "page= 180\n",
      "page= 181\n",
      "page= 182\n",
      "page= 183\n",
      "page= 184\n",
      "page= 185\n",
      "page= 186\n",
      "page= 187\n",
      "page= 188\n",
      "page= 189\n",
      "page= 190\n",
      "page= 191\n",
      "page= 192\n",
      "page= 193\n",
      "page= 194\n",
      "page= 195\n",
      "page= 196\n",
      "page= 197\n",
      "page= 198\n",
      "page= 199\n",
      "page= 200\n",
      "page= 201\n",
      "page= 202\n",
      "page= 203\n",
      "page= 204\n",
      "page= 205\n",
      "page= 206\n",
      "page= 207\n",
      "page= 208\n",
      "page= 209\n",
      "page= 210\n",
      "page= 211\n",
      "page= 212\n",
      "page= 213\n",
      "page= 214\n",
      "page= 215\n",
      "page= 216\n",
      "page= 217\n",
      "page= 218\n",
      "page= 219\n",
      "page= 220\n",
      "page= 221\n",
      "page= 222\n",
      "page= 223\n",
      "page= 224\n",
      "page= 225\n",
      "page= 226\n",
      "page= 227\n",
      "page= 228\n",
      "page= 229\n",
      "page= 230\n",
      "page= 231\n",
      "page= 232\n",
      "page= 233\n",
      "page= 234\n",
      "page= 235\n",
      "page= 236\n",
      "page= 237\n",
      "page= 238\n",
      "page= 239\n",
      "page= 240\n",
      "page= 241\n",
      "page= 242\n",
      "page= 243\n",
      "page= 244\n",
      "page= 245\n",
      "page= 246\n",
      "page= 247\n",
      "page= 248\n",
      "page= 249\n",
      "page= 250\n",
      "page= 251\n",
      "page= 252\n",
      "page= 253\n",
      "page= 254\n",
      "page= 255\n",
      "page= 256\n",
      "page= 257\n",
      "page= 258\n",
      "page= 259\n",
      "page= 260\n",
      "page= 261\n",
      "page= 262\n",
      "page= 263\n",
      "page= 264\n",
      "page= 265\n",
      "page= 266\n",
      "page= 267\n",
      "page= 268\n",
      "page= 269\n",
      "page= 270\n",
      "page= 271\n",
      "page= 272\n",
      "page= 273\n",
      "page= 274\n",
      "page= 275\n",
      "page= 276\n",
      "page= 277\n",
      "page= 278\n",
      "page= 279\n",
      "page= 280\n",
      "page= 281\n",
      "page= 282\n",
      "page= 283\n",
      "page= 284\n",
      "page= 285\n",
      "page= 286\n",
      "page= 287\n",
      "page= 288\n",
      "page= 289\n",
      "page= 290\n",
      "page= 291\n",
      "page= 292\n",
      "page= 293\n",
      "page= 294\n",
      "page= 295\n",
      "page= 296\n",
      "page= 297\n",
      "page= 298\n",
      "page= 299\n",
      "page= 300\n",
      "page= 301\n",
      "page= 302\n",
      "page= 303\n",
      "page= 304\n",
      "page= 305\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-6ee6f1055e64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"#pl_service_showcomplaint tr a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mclick_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://service.account.weibo.com\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclick_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#爬取谣言url\n",
    "browser.get(\"https://service.account.weibo.com/index?type=5&status=0&page=1\")# + str(page))\n",
    "\n",
    "for page in range(1,501):\n",
    "    print(\"page=\",page)\n",
    "    browser.get(\"https://service.account.weibo.com/index?type=5&status=0&page=\" + str(page))\n",
    "    time.sleep(random.uniform(3,6))\n",
    "    mid = []\n",
    "    content = bs(browser.page_source,\"html.parser\",from_encoding='utf-8')\n",
    "    a= content.select(\"#pl_service_showcomplaint tr a\")[::3]\n",
    "    for i in range(20):\n",
    "        click_url = a[i].attrs['href']\n",
    "        browser.get(\"https://service.account.weibo.com\" + click_url)\n",
    "        time.sleep(random.uniform(3,6))\n",
    "        try:\n",
    "            f = browser.find_element(By.XPATH,'//*[@id=\"pl_service_common\"]/div[4]/div[2]/div/div/div/div/p/a')\n",
    "        except:\n",
    "            continue\n",
    "        mid.append(f.get_attribute('href'))\n",
    "    with open(\"url.txt\",\"a\",encoding=\"utf-8\") as f:\n",
    "        mid = \"\\n\".join(mid) + '\\n'\n",
    "        f.writelines(mid)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = browser.find_element_by_xpath('//*[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div/div[4]/div/div[3]/div[2]/div/div/div[1]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'天使芯-保护动物'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.find_element_by_xpath('./div[2]/div[1]/a[1]').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div/div[4]/div/div[3]/div[2]/div/div/div[1]\n",
    "[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div/div[4]/div/div[3]/div[2]/div/div/div[1]/div[2]/div[5]/div/div[1]/div/a[2]\n",
    "[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div/div[4]/div/div[3]/div[2]/div/div/div[1]/div[2]/div[5]/div/div[31]/div/a\n",
    "//*[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div/div[4]/div/div[3]/div[2]/div/div/div[1]/div[2]/div[1]/a[1]\n",
    "//*[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div/div[4]/div/div[3]/div[2]/div/div/div[1]/div[2]/div[3]/div[2]\n",
    "//*[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div/div[4]/div/div[3]/div[2]/div/div/div[1]/div[2]/div[1]\n",
    "//*[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div/div[4]/div/div[3]/div[2]/div/div/div[1]/div[2]/div[1]/text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"e94abfffd909873c73451a5a2d670e03\", element=\"2b04b99d-bce0-49c0-8d7f-ee543a5f1feb\")>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "browser.find_element_by_xpath('//*[@id=\"Pl_Official_WeiboDetail__73\"]/div/div/div/div[4]/div/div[3]/div[2]/div/div/div[29]/div[2]/div[5]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'斩幽冥：是挺残忍，可是根源在警察吗？爱狗人士有心拍照片，为啥不先救下来，等他主人来找呢？那个狗主人为啥把狗弄丢呢？ 警察合理执法，你们这些爱狗人士有意见？这么牛逼，怎么不去堵警察局啊？网上当什么云爱狗人士呢'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1381419600"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeStamp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0950db3d28c512449d89f2219669243e5f33c22ce052a0669b40a9cc1c03615b6",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}